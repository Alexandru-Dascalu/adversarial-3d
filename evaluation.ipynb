{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9405efd-e82c-4765-b7fb-a68e7b467f6f",
   "metadata": {},
   "source": [
    "## Evaluating adversarial textures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6901eac2-1a9d-4b40-8a1f-d6ae5973c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import data\n",
    "import diff_rendering\n",
    "import renderer\n",
    "from config import cfg\n",
    "from imagenet_labels import imagenet_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a21f37-97d2-490e-9f8a-b7768e60ca42",
   "metadata": {},
   "source": [
    "Methods for rendering images used for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f8b2234-f0a6-4a00-adc5-67f2ea27bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_images_for_texture(std_texture, adv_texture, uv_renderer, model_name, target_label):\n",
    "    \"\"\"\n",
    "    Renders evaluation images for a certain 3D model and target label.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    std_texture : numpy array\n",
    "        A numpy array with shape [image_height, image_width, 3]. Represents the normal texture of the 3D model.\n",
    "    adv_texture : numpy array\n",
    "        A numpy array with shape [image_height, image_width, 3]. Represents an adversarial texture of the 3D model.\n",
    "    uv_renderer : Renderer\n",
    "        The renderer used to create the UV maps used to create the images.\n",
    "    model_name : str\n",
    "        The name of the 3D model. Only matters for saving the rendered images to a file.\n",
    "    target_label : int\n",
    "        Target label for which the given adversarial texture was made. Only matters for saving the rendered images to a\n",
    "        file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Two tensors. The first one is of shape 100 x 299 x 299 x 3, representing the images of the new\n",
    "        renders with the normal texture. The second is of shape 100 x 299 x 299 x 3, representing the\n",
    "        images of the new renders with the adversarial texture.\n",
    "    \"\"\"\n",
    "    std_images = []\n",
    "    adv_images = []\n",
    "    for i in range(100):\n",
    "        std_image, adv_image = render_image_for_texture(std_texture, adv_texture, uv_renderer)\n",
    "        std_images.append(std_image)\n",
    "        adv_images.append(adv_image)\n",
    "\n",
    "        save_rendered_images(std_image, adv_image, model_name, target_label, i)\n",
    "\n",
    "    # convert list of numpy images to one single numpy array\n",
    "    std_images = np.stack(std_images, axis=0)\n",
    "    adv_images = np.stack(adv_images, axis=0)\n",
    "    # scale images from 0 to 1 values to values between -1 and 1, as that is what neural networks expect\n",
    "    std_images = 2 * std_images - 1\n",
    "    adv_images = 2 * adv_images - 1\n",
    "\n",
    "    return std_images, adv_images\n",
    "\n",
    "\n",
    "def render_image_for_texture(std_texture, adv_texture, renderer):\n",
    "    \"\"\"\n",
    "    Renders a pair of two evaluation images for a certain 3D model and target label. One image uses the normal texture,\n",
    "    while the other has the exact same pose of the 3D object, background colour, and other params, but uses the\n",
    "    adversarial texture instead.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    std_texture : numpy array\n",
    "        A numpy array with shape [image_height, image_width, 3]. Represents the normal texture of the 3D model.\n",
    "    adv_texture : numpy array\n",
    "        A numpy array with shape [image_height, image_width, 3]. Represents an adversarial texture of the 3D model.\n",
    "    uv_renderer : Renderer\n",
    "        The renderer used to create the UV maps used to create the images.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Two tensors. The first one is of shape 299 x 299 x 3, representing the image of the new renders with the normal\n",
    "        texture. The second is of shape 299 x 299 x 3, representing the images of the new renders with the adversarial\n",
    "        texture.\n",
    "    \"\"\"\n",
    "    width = std_texture.shape[1]\n",
    "    height = std_texture.shape[0]\n",
    "\n",
    "    uv_map = renderer.render(1)\n",
    "    uv_map = uv_map * np.asarray([width - 1, height - 1], dtype=np.float32)\n",
    "\n",
    "    std_image, adv_image = diff_rendering.render(std_texture, adv_texture, uv_map)\n",
    "\n",
    "    # convert tensors to numpy arrays and discard the batch dimension\n",
    "    std_image = std_image.numpy()[0]\n",
    "    adv_image = adv_image.numpy()[0]\n",
    "\n",
    "    return std_image, adv_image\n",
    "\n",
    "\n",
    "def save_rendered_images(std_image, adv_image, model_name, target_label, num_image):\n",
    "    \"\"\"\n",
    "    Save a pair of evaluation images to the file system.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    std_image : numpy array\n",
    "        A numpy array with shape [image_height, image_width, 3]. Represents an image with the normal texture.\n",
    "    adv_image : numpy array\n",
    "        A numpy array with shape [image_height, image_width, 3]. Represents an image with the adversarial texture.\n",
    "    model_name : str\n",
    "        The name of the 3D model rendered in these images.\n",
    "    target_label : int\n",
    "        Target label for which the adversarial texture in adv_image was made.\n",
    "    num_image : int\n",
    "        The index of this pair of renders. Used to give the file name a unique name.\n",
    "    \"\"\"\n",
    "    if not os.path.exists('./evaluation_images/normal/{}'.format(model_name)):\n",
    "        os.makedirs('./evaluation_images/normal/{}'.format(model_name))\n",
    "\n",
    "    if not os.path.exists('./evaluation_images/normal/{}/{}'.format(model_name, target_label)):\n",
    "        os.makedirs('./evaluation_images/normal/{}/{}'.format(model_name, target_label))\n",
    "\n",
    "    if not os.path.exists('./evaluation_images/adv/{}'.format(model_name)):\n",
    "        os.makedirs('./evaluation_images/adv/{}'.format(model_name))\n",
    "\n",
    "    if not os.path.exists('./evaluation_images/adv/{}/{}'.format(model_name, target_label)):\n",
    "        os.makedirs('./evaluation_images/adv/{}/{}'.format(model_name, target_label))\n",
    "\n",
    "    # Pillow only accepts numpy arrays with integer values as valid images\n",
    "    std_image = (std_image * 255).astype('uint8')\n",
    "    adv_image = (adv_image * 255).astype('uint8')\n",
    "\n",
    "    Image.fromarray(std_image, 'RGB').save('./evaluation_images/normal/{}/{}/image_{}.jpg'.format(\n",
    "        model_name, target_label, num_image))\n",
    "    Image.fromarray(adv_image, 'RGB').save('./evaluation_images/adv/{}/{}/image_{}.jpg'.format(\n",
    "        model_name, target_label, num_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e70e88-c0b3-416f-b557-c246d941e423",
   "metadata": {},
   "source": [
    "Methods for calculating TFR and accuracy based on the logits from the victim model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd4dbee8-9cce-4e24-8d05-7616a9e4207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_prediction_true(true_labels, predicted_label):\n",
    "    \"\"\"\n",
    "    Check if predicted label is a ground truth label.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    true_labels : list\n",
    "        The list of ground truth labels for a 3D model.\n",
    "    predicted_label : int\n",
    "        The predicted label.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if the prediction is correct, false if not.\n",
    "    \"\"\"\n",
    "    if true_labels == \"dog\":\n",
    "        # dog model has all 120 dog breed and dog-like animals as true labels\n",
    "        if 150 < predicted_label < 276:\n",
    "            return True\n",
    "    # even if object only has one true label, it is still represented as a list with just one element\n",
    "    elif type(true_labels) == list:\n",
    "        if predicted_label in true_labels:\n",
    "            return True\n",
    "    else:\n",
    "        raise ValueError(\"true labels list for a sample should be either \\\"dog\\\" or a list of ints.\")\n",
    "\n",
    "    # if it has not returned so far, then the prediction is incorrect\n",
    "    return False\n",
    "\n",
    "def get_tfr_and_accuracy(model, target_label, predictions):\n",
    "    \"\"\"\n",
    "    Calculate TFR and classification accuracy for a set of predictions made by a neural network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : data.Model3D\n",
    "        The 3D model in the rendered images for which predictions were made.\n",
    "    target_label : int\n",
    "        Adversarial target label that we want to measure TFR for.\n",
    "    predictions : numpy array\n",
    "        The raw logits that the neural network outputed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A tuple with two values. The first is the accuracy, the second is the TFR.\n",
    "    \"\"\"\n",
    "    label_predictions = [np.argmax(prediction) for prediction in predictions]\n",
    "\n",
    "    accuracy = sum([is_prediction_true(model.labels, predicted_label) for predicted_label in label_predictions])\n",
    "    accuracy = accuracy / len(label_predictions)\n",
    "\n",
    "    tfr = sum([target_label == predicted_label for predicted_label in label_predictions])\n",
    "    tfr  = tfr / len(label_predictions)\n",
    "\n",
    "    return accuracy, tfr\n",
    "\n",
    "\n",
    "def save_result(result_dict, result, model_name, target_label, tfr):\n",
    "    \"\"\"\n",
    "    Save tfr or accuracy evaluation result to a dictionary based on the model and target label of the texture that was\n",
    "    evaluated.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    result_dict : dict\n",
    "        Nested dictionary holding experiment results. It has an entry for each 3D model, mapping the model name to\n",
    "        another dictionary. This dictionary has an entry for each target label for which an adversarial texture was\n",
    "        made. The key is the int target label, and the value is another dictionary. This dictionary has two entries,\n",
    "        one for the tfr and the other for the classification accuracy. The key must be 'tfr'/'accuracy' and the value\n",
    "        is a float number between 0 and 1.\n",
    "    result : float\n",
    "        The value of a measurement metric we want to save in the dictionary. The metric is either is for the TFR or for\n",
    "        the classification accuracy\n",
    "    model_name : str\n",
    "        The name of the 3D model for the given result was recorded.\n",
    "    target_label : int\n",
    "        The target label for which the given result was recorded.\n",
    "    tfr : bool\n",
    "        Whether the given result is the TFR or not.\n",
    "    \"\"\"\n",
    "    # initialise sub-dictionary for that particular model\n",
    "    if model_name not in result_dict:\n",
    "        result_dict[model_name] = dict()\n",
    "\n",
    "    # initialise sub-dictionary for that particular target label in the sub-dictionary for the given model\n",
    "    if target_label not in result_dict[model_name]:\n",
    "        result_dict[model_name][target_label] = dict()\n",
    "\n",
    "    # we may want to either save the TFR of adversarial texture or its accuracy\n",
    "    if tfr:\n",
    "        result_dict[model_name][target_label]['tfr'] = result\n",
    "    else:\n",
    "        result_dict[model_name][target_label]['accuracy'] = result\n",
    "        \n",
    "def save_num_steps(num_steps_dict, num_steps, model_name, target_label):\n",
    "    \"\"\"\n",
    "    Save number of EOT optimisation steps used to create an adversarial texture. It is saved to a dictionary based on\n",
    "    the model and target label of the texture.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_steps_dict : dict\n",
    "        Nested dictionary holding experiment results. It has an entry for each 3D model, mapping the model name to\n",
    "        another dictionary. This dictionary has an entry for each target label for which an adversarial texture was\n",
    "        made. The key is the int target label, and the value is the number of steps for the texture of that 3D model\n",
    "        and that target label.\n",
    "    num_steps : int\n",
    "        The number of EOT optimisation steps that took to create that adversarial texture.\n",
    "    model_name : str\n",
    "        The name of the 3D model for the given result was recorded.\n",
    "    target_label : int\n",
    "        The target label for which the given result was recorded.\n",
    "    \"\"\"\n",
    "    # initialise sub-dictionary for that particular model\n",
    "    if model_name not in num_steps_dict:\n",
    "        num_steps_dict[model_name] = dict()\n",
    "\n",
    "    # initialise sub-dictionary for that particular target label in the sub-dictionary for the given model\n",
    "    if target_label not in num_steps_dict[model_name]:\n",
    "        num_steps_dict[model_name][target_label] = dict()\n",
    "\n",
    "    num_steps_dict[model_name][target_label] = num_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f762762-fee1-4d35-8520-beafae5c9a67",
   "metadata": {},
   "source": [
    "Methods for calculating averages of results saved in the dictionaries for normal and adversarial images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "659a5573-b04c-4716-9d54-451fbc38d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_metric(results_dict, for_tfr):\n",
    "    \"\"\"\n",
    "    Calculate average of the TFR/classification accuracy across all 3D models.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results_dict : dict\n",
    "        Nested dictionary holding experiment results. It has an entry for each 3D model, mapping the model name to\n",
    "        another dictionary. This dictionary has an entry for each target label for which an adversarial texture was\n",
    "        made. The key is the int target label, and the value is another dictionary. This dictionary has two entries,\n",
    "        one for the tfr and the other for the classification accuracy. The key must be 'tfr'/'accuracy' and the value\n",
    "        is a float number between 0 and 1.\n",
    "    for_tfr : bool\n",
    "        Whether we calculate the mean of the TFR, or of the classification accuracy.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The mean TFR or classification accuracy across all 3D models for which there are results in results_dict.\n",
    "    \"\"\"\n",
    "    metric_sum = 0\n",
    "    metric_count = 0\n",
    "\n",
    "    for model_name in results_dict:\n",
    "        metric_sum += get_average_metric_for_model(results_dict, model_name, for_tfr)\n",
    "        metric_count += 1\n",
    "\n",
    "    average = metric_sum / metric_count\n",
    "    return average\n",
    "\n",
    "\n",
    "def get_average_metric_for_model(results_dict, model_name, for_tfr):\n",
    "    \"\"\"\n",
    "    Calculate average of the TFR/classification accuracy for all adversarial textures of the given 3D model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results_dict : dict\n",
    "        Nested dictionary holding experiment results. It has an entry for each 3D model, mapping the model name to\n",
    "        another dictionary. This dictionary has an entry for each target label for which an adversarial texture was\n",
    "        made. The key is the int target label, and the value is another dictionary. This dictionary has two entries,\n",
    "        one for the tfr and the other for the classification accuracy. The key must be 'tfr'/'accuracy' and the value\n",
    "        is a float number between 0 and 1.\n",
    "    model_name : str\n",
    "        The name of the 3D model for which the mean is calculated.\n",
    "    for_tfr : bool\n",
    "        Whether we calculate the mean of the TFR, or of the classification accuracy.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The mean TFR or classification accuracy for one 3D model for which there are results in results_dict.\n",
    "    \"\"\"\n",
    "    metric_sum = 0\n",
    "    metric_count = 0\n",
    "\n",
    "    for target_label in results_dict[model_name]:\n",
    "        if for_tfr:\n",
    "            metric_sum += results_dict[model_name][target_label]['tfr']\n",
    "        else:\n",
    "            metric_sum += results_dict[model_name][target_label]['accuracy']\n",
    "        metric_count += 1\n",
    "\n",
    "    average = metric_sum / metric_count\n",
    "    return average\n",
    "\n",
    "def get_average_num_steps(num_steps_dict, model_name):\n",
    "    \"\"\"\n",
    "    Calculate average of the TFR/classification accuracy for all adversarial textures of the given 3D model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_steps_dict : dict\n",
    "        Nested dictionary holding experiment results. It has an entry for each 3D model, mapping the model name to\n",
    "        another dictionary. This dictionary has an entry for each target label for which an adversarial texture was\n",
    "        made. The key is the int target label, and the value is the number of steps for the texture of that 3D model\n",
    "        and that target label.\n",
    "    model_name : str\n",
    "        The name of the 3D model for which the mean is calculated.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The mean number of steps it took to create adversarial textures for the given model.\n",
    "    \"\"\"\n",
    "    num_steps_sum = 0\n",
    "    num_steps_count = 0\n",
    "\n",
    "    for target_label in num_steps_dict[model_name]:\n",
    "        num_steps_sum += num_steps_dict[model_name][target_label]\n",
    "        num_steps_count += 1\n",
    "\n",
    "    average = num_steps_sum / num_steps_count\n",
    "    return average\n",
    "\n",
    "def flatten_dict(result_dict, for_tfr):\n",
    "    \"\"\"\n",
    "    Serialises the the results dict into a list.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    result_dict : dict\n",
    "        Nested dictionary holding experiment results. It has an entry for each 3D model, mapping the model name to\n",
    "        another dictionary. This dictionary has an entry for each target label for which an adversarial texture was\n",
    "        made. The key is the int target label, and the value is another dictionary. This dictionary has two entries,\n",
    "        one for the tfr and the other for the classification accuracy. The key must be 'tfr'/'accuracy' and the value\n",
    "        is a float number between 0 and 1.\n",
    "    for_tfr : bool\n",
    "        Whether the given result if the TFR or not.\n",
    "    \"\"\"\n",
    "    result_list = []\n",
    "    for model in result_dict:\n",
    "        for target_label in result_dict[model]:\n",
    "            if for_tfr:\n",
    "                result_list.append(result_dict[model][target_label]['tfr'])\n",
    "            else:\n",
    "                result_list.append(result_dict[model][target_label]['accuracy'])\n",
    "\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e47fc-1387-489d-b9a9-46d9575a0529",
   "metadata": {},
   "source": [
    "Methods for parsing file names of adversarial textures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03826695-a9bf-40a7-bd5d-b8bae8ebf9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_adv_texture_file_name(file_name):\n",
    "    \"\"\"\n",
    "    Extracts useful information from the name of the files where the adversarial examples were saved.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name : str\n",
    "        The name of the file.\n",
    "    \"\"\"\n",
    "    # removed extension from image file name\n",
    "    file_name, _ = os.path.splitext(file_name)\n",
    "    file_name_split = file_name.split('_')\n",
    "\n",
    "    target_label = int(file_name_split[-3])\n",
    "    num_steps = int(file_name_split[-1])\n",
    "\n",
    "    index_first_digit = get_index_first_digit(file_name)\n",
    "    # before the first digit in the file name, there is an underscore, which is not part of the name. Therefore we\n",
    "    # slice until index_first_digit - 1\n",
    "    model_name = file_name[:(index_first_digit - 1)]\n",
    "\n",
    "    return model_name, target_label, num_steps\n",
    "\n",
    "\n",
    "def get_index_first_digit(string):\n",
    "    \"\"\"\n",
    "    Returns index of the first digit to be found in a string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    string : str\n",
    "        The string to be searched.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Index where the first digit can be found.\n",
    "    \"\"\"\n",
    "    for i, character in enumerate(string):\n",
    "        if character.isdigit():\n",
    "            return i\n",
    "    raise ValueError(\"The given string is expectde to have numbers in it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380b8270-9ea4-44b2-b8f4-d7cdafd0ae69",
   "metadata": {},
   "source": [
    "Creating necessary objects for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6118173-508a-429d-95dc-b8c7c653b82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "barrel: labels [427]\n",
      "baseball: labels [429]\n",
      "camaro: labels [817, 436, 751]\n",
      "clownfish: labels [393]\n",
      "crocodile: labels [49, 50]\n",
      "german_shepherd: labels dog\n",
      "jeep: labels [609, 586, 408]\n",
      "orange: labels [950]\n",
      "orca: labels [148]\n",
      "purse: labels [748, 893]\n",
      "rugby_ball: labels [768]\n",
      "running_shoe: labels [770]\n",
      "sea_turtle: labels [33, 34, 35, 36, 37]\n",
      "taxi: labels [468]\n",
      "teddy: labels [850]\n"
     ]
    }
   ],
   "source": [
    "models = data.load_dataset(\"./dataset\")\n",
    "\n",
    "# make renderer used for creating UV maps\n",
    "uv_renderer = renderer.Renderer((299, 299))\n",
    "uv_renderer.set_parameters(\n",
    "    camera_distance=(cfg.camera_distance_min, cfg.camera_distance_max),\n",
    "    x_translation=(cfg.x_translation_min, cfg.x_translation_max),\n",
    "    y_translation=(cfg.y_translation_min, cfg.y_translation_max)\n",
    ")\n",
    "\n",
    "victim_model = tf.keras.applications.inception_v3.InceptionV3(\n",
    "    include_top=True,\n",
    "    weights='imagenet',\n",
    "    classes=1000,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "victim_model.compile(optimizer='adam',\n",
    "                     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb45fd6-4f88-4e41-99f6-3ea05a4e2de3",
   "metadata": {},
   "source": [
    "For every adversarial texture, render 100 evaluation images of that model with the adversarial texture, together with 100 images using the normal texture of that model, but using the exact same positions and backgrounds as the adversarial images. Then use the victim model to evaluate how often are these images labelled with a correct label vs the target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c400556-dc4f-4c43-a2a8-209e4b97a3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating evaluation renders for model barrel, target label 553 (file, file cabinet, filing cabinet)\n",
      "100/100 [==============================] - 13s 51ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.9\n",
      "100/100 [==============================] - 5s 52ms/step\n",
      "Evaluating adversarial images: TFR: 0.97, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model barrel, target label 604 (hourglass)\n",
      "100/100 [==============================] - 5s 50ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.93\n",
      "100/100 [==============================] - 5s 49ms/step\n",
      "Evaluating adversarial images: TFR: 0.98, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model barrel, target label 683 (oboe, hautboy, hautbois)\n",
      "100/100 [==============================] - 5s 49ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.92\n",
      "100/100 [==============================] - 5s 49ms/step\n",
      "Evaluating adversarial images: TFR: 0.89, Accuracy: 0.01\n",
      "\n",
      "Creating evaluation renders for model barrel, target label 748 (purse)\n",
      "100/100 [==============================] - 5s 47ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.93\n",
      "100/100 [==============================] - 5s 52ms/step\n",
      "Evaluating adversarial images: TFR: 1.0, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model barrel, target label 878 (typewriter keyboard)\n",
      "100/100 [==============================] - 5s 52ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.96\n",
      "100/100 [==============================] - 5s 51ms/step\n",
      "Evaluating adversarial images: TFR: 0.94, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model baseball, target label 193 (Australian terrier)\n",
      "100/100 [==============================] - 5s 54ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 1.0\n",
      "100/100 [==============================] - 5s 50ms/step\n",
      "Evaluating adversarial images: TFR: 0.57, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model baseball, target label 273 (dingo, warrigal, warragal, Canis dingo)\n",
      "100/100 [==============================] - 5s 52ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 1.0\n",
      "100/100 [==============================] - 5s 50ms/step\n",
      "Evaluating adversarial images: TFR: 0.67, Accuracy: 0.09\n",
      "\n",
      "Creating evaluation renders for model baseball, target label 385 (Indian elephant, Elephas maximus)\n",
      "100/100 [==============================] - 5s 54ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 1.0\n",
      "100/100 [==============================] - 5s 52ms/step\n",
      "Evaluating adversarial images: TFR: 0.86, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model baseball, target label 753 (radiator)\n",
      "100/100 [==============================] - 5s 54ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 1.0\n",
      "100/100 [==============================] - 5s 47ms/step\n",
      "Evaluating adversarial images: TFR: 0.98, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model baseball, target label 895 (warplane, military plane)\n",
      "100/100 [==============================] - 5s 51ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 1.0\n",
      "100/100 [==============================] - 5s 51ms/step\n",
      "Evaluating adversarial images: TFR: 0.95, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model camaro, target label 21 (kite)\n",
      "100/100 [==============================] - 5s 49ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.12\n",
      "100/100 [==============================] - 5s 50ms/step\n",
      "Evaluating adversarial images: TFR: 0.92, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model camaro, target label 298 (mongoose)\n",
      "100/100 [==============================] - 5s 53ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.11\n",
      "100/100 [==============================] - 5s 49ms/step\n",
      "Evaluating adversarial images: TFR: 0.95, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model camaro, target label 384 (indri, indris, Indri indri, Indri brevicaudatus)\n",
      "100/100 [==============================] - 5s 52ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.13\n",
      "100/100 [==============================] - 5s 50ms/step\n",
      "Evaluating adversarial images: TFR: 0.96, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model camaro, target label 875 (trombone)\n",
      "100/100 [==============================] - 5s 55ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.08\n",
      "100/100 [==============================] - 5s 52ms/step\n",
      "Evaluating adversarial images: TFR: 0.93, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model camaro, target label 98 (red-breasted merganser, Mergus serrator)\n",
      "100/100 [==============================] - 5s 52ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.1\n",
      "100/100 [==============================] - 5s 52ms/step\n",
      "Evaluating adversarial images: TFR: 0.91, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model clownfish, target label 433 (bathing cap, swimming cap)\n",
      "100/100 [==============================] - 5s 53ms/step\n",
      "Evaluating normal images: TFR: 0.04, Accuracy: 0.3\n",
      "100/100 [==============================] - 5s 51ms/step\n",
      "Evaluating adversarial images: TFR: 0.68, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model clownfish, target label 579 (grand piano, grand)\n",
      "100/100 [==============================] - 5s 53ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.38\n",
      "100/100 [==============================] - 5s 51ms/step\n",
      "Evaluating adversarial images: TFR: 0.0, Accuracy: 0.03\n",
      "\n",
      "Creating evaluation renders for model clownfish, target label 790 (shopping basket)\n",
      "100/100 [==============================] - 7s 66ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.37\n",
      "100/100 [==============================] - 6s 55ms/step\n",
      "Evaluating adversarial images: TFR: 0.71, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model clownfish, target label 892 (wall clock)\n",
      "100/100 [==============================] - 5s 54ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.44\n",
      "100/100 [==============================] - 5s 52ms/step\n",
      "Evaluating adversarial images: TFR: 0.5, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model clownfish, target label 982 (groom, bridegroom)\n",
      "100/100 [==============================] - 5s 55ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.37\n",
      "100/100 [==============================] - 5s 52ms/step\n",
      "Evaluating adversarial images: TFR: 0.52, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model german_shepherd, target label 22 (bald eagle, American eagle, Haliaeetus leucocephalus)\n",
      "100/100 [==============================] - 5s 54ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.71\n",
      "100/100 [==============================] - 5s 52ms/step\n",
      "Evaluating adversarial images: TFR: 0.82, Accuracy: 0.01\n",
      "\n",
      "Creating evaluation renders for model german_shepherd, target label 427 (barrel, cask)\n",
      "100/100 [==============================] - 5s 54ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.71\n",
      "100/100 [==============================] - 5s 53ms/step\n",
      "Evaluating adversarial images: TFR: 0.76, Accuracy: 0.08\n",
      "\n",
      "Creating evaluation renders for model german_shepherd, target label 445 (bikini, two-piece)\n",
      "100/100 [==============================] - 5s 53ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.76\n",
      "100/100 [==============================] - 5s 52ms/step\n",
      "Evaluating adversarial images: TFR: 0.92, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model german_shepherd, target label 80 (black grouse)\n",
      "100/100 [==============================] - 5s 53ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.77\n",
      "100/100 [==============================] - 5s 52ms/step\n",
      "Evaluating adversarial images: TFR: 0.89, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model german_shepherd, target label 93 (hornbill)\n",
      "100/100 [==============================] - 5s 52ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.71\n",
      "100/100 [==============================] - 5s 51ms/step\n",
      "Evaluating adversarial images: TFR: 0.89, Accuracy: 0.02\n",
      "\n",
      "Creating evaluation renders for model orange, target label 172 (whippet)\n",
      "100/100 [==============================] - 5s 53ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.65\n",
      "100/100 [==============================] - 5s 52ms/step\n",
      "Evaluating adversarial images: TFR: 0.99, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model orange, target label 572 (goblet)\n",
      "100/100 [==============================] - 4s 41ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.58\n",
      "100/100 [==============================] - 4s 37ms/step\n",
      "Evaluating adversarial images: TFR: 1.0, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model orange, target label 626 (lighter, light, igniter, ignitor)\n",
      "100/100 [==============================] - 4s 37ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.61\n",
      "100/100 [==============================] - 4s 37ms/step\n",
      "Evaluating adversarial images: TFR: 0.93, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model orange, target label 657 (missile)\n",
      "100/100 [==============================] - 4s 39ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.52\n",
      "100/100 [==============================] - 4s 37ms/step\n",
      "Evaluating adversarial images: TFR: 0.95, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model orange, target label 923 (plate)\n",
      "100/100 [==============================] - 4s 38ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.59\n",
      "100/100 [==============================] - 4s 38ms/step\n",
      "Evaluating adversarial images: TFR: 1.0, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model purse, target label 180 (American Staffordshire terrier, Staffordshire terrier, American pit bull terrier, pit bull terrier)\n",
      "100/100 [==============================] - 4s 43ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.75\n",
      "100/100 [==============================] - 4s 37ms/step\n",
      "Evaluating adversarial images: TFR: 0.1, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model purse, target label 19 (chickadee)\n",
      "100/100 [==============================] - 4s 39ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.64\n",
      "100/100 [==============================] - 4s 37ms/step\n",
      "Evaluating adversarial images: TFR: 0.24, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model purse, target label 274 (dhole, Cuon alpinus)\n",
      "100/100 [==============================] - 4s 38ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.71\n",
      "100/100 [==============================] - 4s 38ms/step\n",
      "Evaluating adversarial images: TFR: 0.62, Accuracy: 0.04\n",
      "\n",
      "Creating evaluation renders for model purse, target label 307 (weevil)\n",
      "100/100 [==============================] - 4s 39ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.66\n",
      "100/100 [==============================] - 4s 36ms/step\n",
      "Evaluating adversarial images: TFR: 0.91, Accuracy: 0.01\n",
      "\n",
      "Creating evaluation renders for model purse, target label 977 (sandbar, sand bar)\n",
      "100/100 [==============================] - 4s 39ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.79\n",
      "100/100 [==============================] - 4s 37ms/step\n",
      "Evaluating adversarial images: TFR: 0.27, Accuracy: 0.06\n",
      "\n",
      "Creating evaluation renders for model sea_turtle, target label 193 (Australian terrier)\n",
      "100/100 [==============================] - 4s 38ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.88\n",
      "100/100 [==============================] - 4s 39ms/step\n",
      "Evaluating adversarial images: TFR: 0.95, Accuracy: 0.01\n",
      "\n",
      "Creating evaluation renders for model sea_turtle, target label 288 (leopard, Panthera pardus)\n",
      "100/100 [==============================] - 4s 38ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.91\n",
      "100/100 [==============================] - 4s 36ms/step\n",
      "Evaluating adversarial images: TFR: 0.99, Accuracy: 0.01\n",
      "\n",
      "Creating evaluation renders for model sea_turtle, target label 315 (mantis, mantid)\n",
      "100/100 [==============================] - 5s 47ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.91\n",
      "100/100 [==============================] - 4s 38ms/step\n",
      "Evaluating adversarial images: TFR: 0.95, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model sea_turtle, target label 516 (cradle)\n",
      "100/100 [==============================] - 4s 38ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.9\n",
      "100/100 [==============================] - 4s 38ms/step\n",
      "Evaluating adversarial images: TFR: 0.29, Accuracy: 0.01\n",
      "\n",
      "Creating evaluation renders for model sea_turtle, target label 731 (plunger, plumber's helper)\n",
      "100/100 [==============================] - 4s 38ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.89\n",
      "100/100 [==============================] - 4s 36ms/step\n",
      "Evaluating adversarial images: TFR: 0.84, Accuracy: 0.01\n",
      "\n",
      "Creating evaluation renders for model taxi, target label 224 (groenendael)\n",
      "100/100 [==============================] - 4s 38ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.11\n",
      "100/100 [==============================] - 4s 38ms/step\n",
      "Evaluating adversarial images: TFR: 0.84, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model taxi, target label 336 (marmot)\n",
      "100/100 [==============================] - 4s 39ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.14\n",
      "100/100 [==============================] - 4s 37ms/step\n",
      "Evaluating adversarial images: TFR: 0.91, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model taxi, target label 402 (acoustic guitar)\n",
      "100/100 [==============================] - 4s 38ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.14\n",
      "100/100 [==============================] - 4s 36ms/step\n",
      "Evaluating adversarial images: TFR: 0.89, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model taxi, target label 516 (cradle)\n",
      "100/100 [==============================] - 4s 39ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.14\n",
      "100/100 [==============================] - 4s 37ms/step\n",
      "Evaluating adversarial images: TFR: 0.83, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model taxi, target label 581 (grille, radiator grille)\n",
      "100/100 [==============================] - 4s 38ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.22\n",
      "100/100 [==============================] - 4s 37ms/step\n",
      "Evaluating adversarial images: TFR: 0.92, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model teddy, target label 202 (soft-coated wheaten terrier)\n",
      "100/100 [==============================] - 4s 39ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.56\n",
      "100/100 [==============================] - 4s 39ms/step\n",
      "Evaluating adversarial images: TFR: 0.99, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model teddy, target label 34 (leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea)\n",
      "100/100 [==============================] - 4s 40ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.5\n",
      "100/100 [==============================] - 4s 38ms/step\n",
      "Evaluating adversarial images: TFR: 0.97, Accuracy: 0.01\n",
      "\n",
      "Creating evaluation renders for model teddy, target label 736 (pool table, billiard table, snooker table)\n",
      "100/100 [==============================] - 4s 38ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.52\n",
      "100/100 [==============================] - 4s 37ms/step\n",
      "Evaluating adversarial images: TFR: 0.91, Accuracy: 0.03\n",
      "\n",
      "Creating evaluation renders for model teddy, target label 926 (hot pot, hotpot)\n",
      "100/100 [==============================] - 4s 41ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.61\n",
      "100/100 [==============================] - 4s 39ms/step\n",
      "Evaluating adversarial images: TFR: 0.63, Accuracy: 0.0\n",
      "\n",
      "Creating evaluation renders for model teddy, target label 953 (pineapple, ananas)\n",
      "100/100 [==============================] - 4s 38ms/step\n",
      "Evaluating normal images: TFR: 0.0, Accuracy: 0.51\n",
      "100/100 [==============================] - 4s 36ms/step\n",
      "Evaluating adversarial images: TFR: 0.95, Accuracy: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dictionaries used to record results of the evaluation. Each dict has sub-dictionaries for each model and\n",
    "# target label\n",
    "normal_results = dict()\n",
    "adv_results = dict()\n",
    "num_steps_dict = dict()\n",
    "\n",
    "for image_file_name in os.listdir(\"./adv_textures\"):\n",
    "    adv_texture = data.Model3D._get_texture(\"./adv_textures/{}\".format(image_file_name))\n",
    "\n",
    "    # extract information from file name of adversarial texture, inclduing which model and target label is the\n",
    "    # texture for\n",
    "    current_model_name, current_target_label, num_steps = parse_adv_texture_file_name(image_file_name)\n",
    "    save_num_steps(num_steps_dict, num_steps, current_model_name, current_target_label)\n",
    "\n",
    "    # find the model that the adversarial texture was made for\n",
    "    current_model = next(x for x in models if x.name == current_model_name)\n",
    "    # get the normal texture of the model\n",
    "    std_texture = current_model.raw_texture\n",
    "    # load the appropriate model into the renderer\n",
    "    uv_renderer.load_obj(current_model.obj_path)\n",
    "\n",
    "    print(\"Creating evaluation renders for model {}, target label {} ({})\".format(\n",
    "        current_model_name, current_target_label, imagenet_labels[current_target_label]))\n",
    "    std_images, adv_images = render_images_for_texture(std_texture, adv_texture, uv_renderer, current_model_name,\n",
    "                                                       current_target_label)\n",
    "\n",
    "    # evaluate renders with the normal image\n",
    "    predictions = victim_model.predict(std_images, batch_size=1)\n",
    "    accuracy, tfr = get_tfr_and_accuracy(current_model, current_target_label, predictions)\n",
    "    # record results in dictionary and on the command line\n",
    "    save_result(normal_results, tfr, current_model_name, current_target_label, tfr=True)\n",
    "    save_result(normal_results, accuracy, current_model_name, current_target_label, tfr=False)\n",
    "    print(\"Evaluating normal images: TFR: {}, Accuracy: {}\".format(tfr, accuracy))\n",
    "\n",
    "    # evaluate renders with the adversarial image\n",
    "    predictions = victim_model.predict(adv_images, batch_size=1)\n",
    "    accuracy, tfr = get_tfr_and_accuracy(current_model, current_target_label, predictions)\n",
    "    # record results in dictionary and on the command line\n",
    "    save_result(adv_results, tfr, current_model_name, current_target_label, tfr=True)\n",
    "    save_result(adv_results, accuracy, current_model_name, current_target_label, tfr=False)\n",
    "    print(\"Evaluating adversarial images: TFR: {}, Accuracy: {}\\n\".format(tfr, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773a4a93-5a29-4b61-8a6b-3b453619e9a4",
   "metadata": {},
   "source": [
    "Calculate mean classification accuracy and TFR for all models and for each individual model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9114eaa8-97d6-483b-b5f3-7d22a01c7c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for normal images: 0.6028\n",
      "Average TFR for normal images: 0.0008\n",
      "Average accuracy for adversarial images: 0.0086\n",
      "Average TFR for adversarial images: 0.8008000000000001\n",
      "\n",
      "\n",
      "Average TFR on adversarial images for model barrel: 0.9559999999999998\n",
      "Average classification accuracy on normal images for model barrel: 0.9280000000000002\n",
      "Average iterations for creating adversarial examples for model barrel: 1428.4\n",
      "\n",
      "Average TFR on adversarial images for model baseball: 0.806\n",
      "Average classification accuracy on normal images for model baseball: 1.0\n",
      "Average iterations for creating adversarial examples for model baseball: 6349.2\n",
      "\n",
      "Average TFR on adversarial images for model camaro: 0.9339999999999999\n",
      "Average classification accuracy on normal images for model camaro: 0.10800000000000001\n",
      "Average iterations for creating adversarial examples for model camaro: 2585.8\n",
      "\n",
      "Average TFR on adversarial images for model clownfish: 0.48200000000000004\n",
      "Average classification accuracy on normal images for model clownfish: 0.372\n",
      "Average iterations for creating adversarial examples for model clownfish: 9999.0\n",
      "\n",
      "Average TFR on adversarial images for model german_shepherd: 0.8560000000000001\n",
      "Average classification accuracy on normal images for model german_shepherd: 0.732\n",
      "Average iterations for creating adversarial examples for model german_shepherd: 5243.0\n",
      "\n",
      "Average TFR on adversarial images for model orange: 0.974\n",
      "Average classification accuracy on normal images for model orange: 0.59\n",
      "Average iterations for creating adversarial examples for model orange: 1163.2\n",
      "\n",
      "Average TFR on adversarial images for model purse: 0.42800000000000005\n",
      "Average classification accuracy on normal images for model purse: 0.7100000000000001\n",
      "Average iterations for creating adversarial examples for model purse: 9090.6\n",
      "\n",
      "Average TFR on adversarial images for model sea_turtle: 0.8039999999999999\n",
      "Average classification accuracy on normal images for model sea_turtle: 0.898\n",
      "Average iterations for creating adversarial examples for model sea_turtle: 5123.0\n",
      "\n",
      "Average TFR on adversarial images for model taxi: 0.8780000000000001\n",
      "Average classification accuracy on normal images for model taxi: 0.15\n",
      "Average iterations for creating adversarial examples for model taxi: 4229.6\n",
      "\n",
      "Average TFR on adversarial images for model teddy: 0.89\n",
      "Average classification accuracy on normal images for model teddy: 0.54\n",
      "Average iterations for creating adversarial examples for model teddy: 2782.8\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy for normal images: {}\".format(get_average_metric(normal_results, for_tfr=False)))\n",
    "print(\"Average TFR for normal images: {}\".format(get_average_metric(normal_results, for_tfr=True)))\n",
    "\n",
    "print(\"Average accuracy for adversarial images: {}\".format(get_average_metric(adv_results, for_tfr=False)))\n",
    "print(\"Average TFR for adversarial images: {}\\n\".format(get_average_metric(adv_results, for_tfr=True)))\n",
    "\n",
    "for model_name in adv_results:\n",
    "    print(\"\\nAverage TFR on adversarial images for model {}: {}\".format(model_name, get_average_metric_for_model(\n",
    "        adv_results, model_name, for_tfr=True)))\n",
    "    print(\"Average classification accuracy on normal images for model {}: {}\".format(\n",
    "        model_name, get_average_metric_for_model(normal_results, model_name, for_tfr=False)))\n",
    "    print(\"Average iterations for creating adversarial examples for model {}: {}\".format(\n",
    "        model_name, get_average_num_steps(num_steps_dict, model_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80e0302-c67d-42b3-83c2-d38a4351308a",
   "metadata": {},
   "source": [
    "Create a histogram of mean TFR for the 50 adversarial textures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "813e412e-8afa-464d-b57b-8dd8ead228d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfr_list = flatten_dict(adv_results, for_tfr=True)\n",
    "plt.hist(tfr_list, bins=20)\n",
    "plt.title(\"Histogram of adversariality in the adversarial images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962075c4-d285-41ae-aefc-46d2e69544f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
